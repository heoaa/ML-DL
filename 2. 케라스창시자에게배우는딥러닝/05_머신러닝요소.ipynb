{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9792bc0b-1dd6-423e-b1e2-05118e6af0ca",
   "metadata": {},
   "source": [
    "## 1. 머신러닝 종류\n",
    "- <b>1) 지도학습</b> : 사람이 레이블링한 타깃에 입력데이터를 매핑하는 방법을 학습<br>\n",
    "(음성인식, 이미지 분류, 언어 번역 등 딥러닝은 지도학슴 범주에 속함)\n",
    "<br><br>\n",
    "- <b>2) 비지도학습</b> : 어떤 타깃도 사용하지 않고 입력데이터에 대한 흥미로운 변환을 찾는 방법,<br>\n",
    "데이터 시각화/압축/노이즈 제거 또는 상관관계를 잘 이해하기 위해 사용하기 때문에 <br>종종 지도학습 전 데이터 셋을 이해하는 단계로도 사용함 (차원축소, 군집이 해당 범주에 속함)\n",
    "<br><br>\n",
    "- <b>3) 자기지도학습</b> : 지도학습이지만 사람이 만든 레이블을 사용하지 않음, 사람이 개입하지 않는 지도학습\n",
    "<br> 지도학습엔 레이블이 필요하기때문에 보통 경험적인 알고리즘을 사용하여 입력데이터로부터 생성함\n",
    "<br><br>\n",
    "- <b>4) 강화학습</b> : 에이전트는 환경에 대한 정보를 받아 보상을 최대화하는 행동을 선택하도록 학습됨(자율주행, 자원관리, 교육 등)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4a2620-f6ce-4a56-b38c-ec676044d6aa",
   "metadata": {},
   "source": [
    "## 2. 머신러닝 모델 평가\n",
    "- <b>1) 단순 홀드아웃 검증</b> : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8409b-64c0-45de-b4a8-c21ad4a57d95",
   "metadata": {},
   "source": [
    "<img src = 'https://blog.kakaocdn.net/dn/bLnseJ/btqL2vT4FWC/PkM3BOqjnkoG5C3cyELOiK/img.png' width ='40%' height='40%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62752a8f-4051-4bea-bf87-f7ccfa8876e5",
   "metadata": {},
   "source": [
    "홀드아웃 검정은 단순해서 데이터가 적을 때는 검증셋과 테스트셋 샘플이 너무 적어 통계적으로 모집단을 대표하지 못할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56177600-38dd-4048-a7fe-364ef218e7d4",
   "metadata": {},
   "source": [
    "- <b>2) k-겹 교차검증</b> : \n",
    "<br><br><img src = 'https://thebook.io/img/006975/130.jpg' width ='60%' height='60%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d130891-c6c9-469f-aa39-adb8e6ad7159",
   "metadata": {},
   "source": [
    "모델의 성능이 데이터 분할에 따라 편차가 클 때 사용하는 방법으로 모델 튜닝에 별개의 검증셋을 사용하게 된다.<br>\n",
    "k-겹 교차검증은 사이킷런의 cross_validate() 함수를 사용하여 쉽게 구현할 수 있다. <br>이 함수를 사용하려면 케라스 모델을 사이킷런과 호환되도록 KerasClassifier나 KerasRegressor 클래스로 모델을 감싸야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e81c75a-5532-4301-8378-80ace7dc7cb6",
   "metadata": {},
   "source": [
    "- <b>3) 셔플링을 사용한 반복 k-겹 교차검증</b> : \n",
    "<br>비교적 가용 데이터가 적고 가능한 정확하게 모델을 평가하고자 할 때 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79825c11-4cec-47d5-a7aa-f85184d71a06",
   "metadata": {},
   "source": [
    "## 3. 신경망을 위한 데이터 전처리\n",
    "- <b>1) 벡터화</b> : 텐서로 변환\n",
    "<br><br>\n",
    "- <b>2) 값 정규화</b> : 각 특성을 독립적으로 정규화하여 평균이 0이고 표준편차가 1이 되도록 표준화\n",
    "<br><br>\n",
    "- <b>3) 누락된 값 다루기</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e398c74-2117-4a74-bbaf-8a6f7a021038",
   "metadata": {},
   "source": [
    "## 4. 과대적합과 과소적합\n",
    "- <b>규제</b> : 과대적합을 피하는 처리 과정\n",
    "<br><br>\n",
    "- <b>1) 네트워크 크기 축소</b> : 과대적합을 막는 가장 단순한 방법은 훈련데이터를 더 모으거나 모델의 크기(학습 파라미터 수)를 줄여 네트워크 용량을 감소시키는 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e1266-164b-49ce-bb0d-99692be16fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26f996b6-5660-4041-9752-0941aa17cb99",
   "metadata": {},
   "source": [
    "- <b>2) 가중치 규제</b> : 과대적합을 완화하기 위한 일반적인 방법은 네트워크 복잡도에 제한을 두어 가중치가 작은 값을 가지도록 강제하는 것이다. <br>가중치 규제를 추가하면 가중치 값의 분포가 더 균일해지며, 네트워크의 손실함수에 큰 가중치와 연관된 비용을 추가한다.\n",
    "- L1 규제 : 가중치의 절댓값에 비례하는 비용이 추가된다.(가중치의 L1 norm)\n",
    "- L2 규제 : 가중치의 제곱에 비례하는 비용이 추가된다.(가중치의 L2 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fa9ee-fcd1-4845-96d0-565732baf97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7697d49-340a-48d1-a666-fcd812f1e355",
   "metadata": {},
   "source": [
    "- <b>3) 드롭아웃</b> : 신경망에 사용되는 규제 기법 중 가장 효과적이고 널리 사용되는 방법 중 하나이다.<br> \n",
    "일정 비율(30%, 50%, 70%)대로 의도적으로 각 층의 노드들을 죽이는(Drop) 기법이다. 일정비율로 각 층의 노드들을 드롭시킴으로써 모델이 특정노드에만 의존하지 않도록 하며, 옆에 노드가 없더라도 옆의 노드들이 여러가지 표현력을 골고루 익힐 수 있도록 하는 효과이다.\n",
    "<br><br>\n",
    "<img src = 'https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F3S4jq%2FbtrhVZcFzHi%2FkPnaKdMCvhHoknqgwWQ4p1%2Fimg.png' width ='60%' height='60%'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c76839-5ca0-4e15-b539-0e98c1307f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation = 'relu', input_shape = (10000, )))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(16, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313bdca5-b704-4365-93ea-c693bfc5c1c9",
   "metadata": {},
   "source": [
    "## 5. 활성화함수와 손실함수 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d3bd6-5ad3-4879-9308-f65c3dff98bb",
   "metadata": {},
   "source": [
    "|<b>문제 유형</b>|마지막 층의 활성화 함수|손실함수|\n",
    "|:-|:-|:-|\n",
    "|이진 분류|sigmoid|binary_crossentropy|\n",
    "|단일 레이블 다중 분류|softmax|categorical_crossentropy|\n",
    "|다중 레이블 다중 분류|sigmoid|binary_crossentropy|\n",
    "|임의 값에 대한 회귀|없음|mse|\n",
    "|0과 1사이 값에 대한 회귀|sigmoid|mse 또는 binary_crossentropy|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django2_kernel",
   "language": "python",
   "name": "django2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
